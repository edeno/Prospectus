### Specific [Aim \#3](#aim3): To build web-enabled interactive visualization tools that enhance exploratory analysis, checking of raw data and statistical modeling assumptions, and data presentation for large, complex and multi-scale electrophyisological data. {#aim3}
Our general goal is to create building blocks for interactive visualizations that can be extended to more complicated visualizations, linked together to provide an integrated view of an electrophysiological dataset --- from raw data to statistical summary or from cellular to circuit level --- or used independently. Each visualization allows for examination of the electrophysiological signals (or summary statistic of the signal) over time relative to task-relevant events, comparison of different subjects or recording sessions, and aggregation of signals over regions-of-interest such as anatomically defined brain areas.

All visualizations will be built in JavaScript using the [D3](http://d3js.org/) library [@bostock_d3_2011] --- a visualization library for translating data into web elements. The D3 library includes support for adding interactions, animations and manipulating data, which is crucial to building the visualizations. This library is well supported and under active development.

All code will be uploaded and documented in a [Github software repository](https://github.com/edeno) and available under the [GNU General Public License, version 2 ](http://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html)--- ensuring that future use and development of the code will remain open source and shareable.

All visualizations will be able to be put into a specific state (e.g. selecting a particular subject, task-relavent event, brain region of interest) by passing parameters via the uniform resource locator (URL) in the browser address bar. This enables the visualizations to be easily shared with other people or to be linked to by other visualizations. In addition, buttons to export a snapshot of the visualization in a specific state (in scalable vector graphics format) will be provided. This makes it easy for a static version of the visualization to be saved and placed in a publication. The New York Times has used this workflow (interactive visualization $\rightarrow$ static visualization in a particular state in print) [successfully](http://chartsnthings.tumblr.com/post/47670081904/climate-change-crowbars-and-strikeouts).

#### RasterVis
The first visualization, RasterVis, incorporates two canonical visualizations for single and multiunit spiking data --- the raster plot and peri-event time histogram. The raster plot describes spike times for each trial relative to a trial event. The peri-event time histogram is a simple but useful summary of how, over a series of trials, the spike times are distributed across time bins relative to the time of a trial event. Because these two types of visualizations are familiar and represent the "raw" spiking data, they are an ideal building-block visualization. Furthermore, they can also be used to compare raw spiking data to model-generated data in order to check statistical modeling assumptions (posterior predictive checks) --- so they can be useful in understanding how models reflect the data.

RasterVis uses interactivity and animation to supplement the raster plot and peri-event time histogram in order to make it easier for the user to accomplish typical tasks in the analysis of spiking data (See [@fig:figure4] for a screenshot of the RasterVis interface).

For example, RasterVis allows for dynamic alignment of spike times and "on-the-fly" computation of peri-event histograms relative to experimental trial events (e.g. visual stimuli, timing of rewards, presentation of fixation points). Animated transitions emphasize how spike timing relative to trial event relates to another. This allows a user to quickly compare the timing of individual spikes and aggregate spiking (via histogram) to different cues and conditions. Different levels of aggregation (Gaussian smoothing) for the histogram can be compared as well.

RasterVis also allows for dynamic sorting by experimental task factors. This feature creates different plots for each condition within the task factor. For example, if a task factor is a visual cue with two experimental conditions --- color and orientation --- sorting by the visual cue creates two plots for the color condition and the orientation condition. This is essential for multidimensional analysis which may compare several different factors and conditions.

Finally, RasterVis allows for comparison between neurons. The user can browse neurons by subject, recording session, or name to easily find and compare neurons.

![A static screenshot of the RasterVis interface.](figures/Figure4.png){#fig:figure4}

#### glmVis
We also will build an interactive visualization for the generalized linear models that will: (1) show the relationship between the multiple dimensions of the model fit over time, (2) show the relationship between multiple models, and (3) show the relationship between multiple brain areas. To show the relationship between multiple dimensions, we will use the parallel coordinate plots [@wegman_hyperdimensional_1990].

![A static screenshot of the glmVis interface.](figures/Figure5.png){#fig:figure5}

#### SpectraVis
Finally, we will build an interactive visualization aimed at capturing functional connectivity between neurons/electrodes. Functional network analysis is a growing area of neuroscience research, driven in part by technological improvements allowing us to record from more sensors simultaneously. However, as researchers record from more sensors, network analyses can become unwieldy and hard to interpret, because the number of possible network connections scales quadratically with the number of sensors (e.g. electrodes). Further, we expect neural processes to form dynamic networks that vary over time, frequency, and spatial scales (e.g. within and between brain regions), adding complexity to network analyses.

SpectraVis is an interactive web-based visualization application that: (1) displays task-related functional networks over time and frequency, (2) compares individual and associative measures on sensor pairs (e.g. spectra, coherences), (3) compares different measures of association (e.g. correlation vs. coherence, binary vs. weighted networks), and (4) views networks at two spatial scales (sensor- and region-of-interest-level). The different modules of SpectraVis are dynamically linked, highlighting relationships between the metrics in response to user interaction.

[@fig:figure6] shows a typical view of SpectraVis. The network view shows the anatomical location of the sensors (circles with sensor number) and edges (lines) weighted by the edge statistic. In this example, the edges are binary, representing significant changes in local field potential coherence between *Speech* --- subjects reading aloud the words of the Gettysburg Address --- and *Silence* at a particular frequency (10 Hz) and time (187.5 ms after speech onset)[^4]. The network has dense connectivity within and between primary motor and primary somatosensory cortices (M1 and S1). The controls can be used to play a movie of the network over time, showing increased connectivity starting within M1 300 ms before speech onset and spreading to S1 100 ms before speech onset.  Below the network view is a sensor view (dotted box) which depicts the relationship (spectra, coherences) between a selected pair of sensors (circled in black, network view, sensors 85 and 90) at all times and frequencies. Here, the edge between M1 (sensor 90) and S1 (sensor 85) represents a 10 Hz increase in speech coherence relative to silence. The increase co-occurs with higher frequency beta (15-25Hz) power suppression on the M1 sensor. Mousing over these displays updates the network view to the time-frequency bin under the cursor.

![A static screenshot of the SpectraVis interface with the ECOG overt reading data.](figures/Figure6.png){#fig:figure6}

#### Potential Pitfalls
A challenge for building software tools is making them easy enough to install and use while making them flexible enough to account for a variety of use cases. Our solution to this is to try to set smart defaults so that the visualization can run without much alteration and to provide extensive documentation and examples via the Github repository for the project. Additionally, we provide Matlab scripts that can help organize data into the correct format.
